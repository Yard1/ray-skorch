{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ray_sklearn import RayTrainNeuralNet\n",
    "from ray_sklearn.models import TabNet\n",
    "from torch import nn\n",
    "from skorch.callbacks import LRScheduler\n",
    "import torch\n",
    "from ranger21.ranger21 import Ranger21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train 2.csv\")\n",
    "target = data[\"hand\"]\n",
    "data = data.drop(\"hand\", axis=1)-1\n",
    "cat_cols = data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = pd.concat([data[col] for col in data.columns if col.startswith(\"C\")], axis=1)\n",
    "num_cols.columns = [f\"n{col}\" for col in num_cols.columns]\n",
    "data = pd.concat((data, num_cols),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RayTrainNeuralNet(\n",
    "    TabNet,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    callbacks=[LRScheduler(torch.optim.lr_scheduler.ReduceLROnPlateau)],\n",
    "    num_workers=1,\n",
    "    max_epochs=50,\n",
    "    batch_size=512,\n",
    "    lr=0.02,\n",
    "    device=\"cpu\",\n",
    "    module__input_dim=data.shape[1],\n",
    "    module__output_dim=10,\n",
    "    module__cat_idxs=list(range(cat_cols)),\n",
    "    module__cat_dims=[data[data.columns[i]].max()+1 for i in range(cat_cols)],\n",
    "    module__cat_emb_dim=[4, 7] * (cat_cols//2),\n",
    "    module__n_d=16, \n",
    "    module__n_a=8,\n",
    "    module__n_steps=1,\n",
    "    #optimizer__num_batches_per_epoch=data.shape[0]//512,\n",
    "    #optimizer__num_epochs=50,\n",
    "    iterator_train__unsqueeze_label_tensor=False,\n",
    "    iterator_valid__unsqueeze_label_tensor=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 00:06:52,663\tINFO trainer.py:172 -- Trainer logs will be logged in: /home/ubuntu/ray_results/train_2021-12-14_00-06-52\n",
      "2021-12-14 00:06:54,114\tINFO trainer.py:178 -- Run results will be logged in: /home/ubuntu/ray_results/train_2021-12-14_00-06-52/run_001\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=1385158)\u001b[0m 2021-12-14 00:06:54,109\tINFO torch.py:66 -- Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=1385158)\u001b[0m 2021-12-14 00:06:54,875\tINFO torch.py:239 -- Moving model to device: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    dur_s\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m1.2382\u001b[0m        \u001b[32m1.0172\u001b[0m   2.4004\n",
      "      2        \u001b[36m0.9908\u001b[0m        \u001b[32m1.0089\u001b[0m   0.9257\n",
      "      3        \u001b[36m0.9853\u001b[0m        \u001b[32m1.0056\u001b[0m   1.0376\n",
      "      4        \u001b[36m0.9812\u001b[0m        \u001b[32m1.0023\u001b[0m   1.1683\n",
      "      5        \u001b[36m0.9782\u001b[0m        \u001b[32m1.0001\u001b[0m   0.9026\n",
      "      6        \u001b[36m0.9752\u001b[0m        \u001b[32m0.9954\u001b[0m   1.2763\n",
      "      7        \u001b[36m0.9681\u001b[0m        0.9983   1.3325\n",
      "      8        0.9684        \u001b[32m0.9921\u001b[0m   1.2943\n",
      "      9        \u001b[36m0.9654\u001b[0m        1.0031   1.2101\n",
      "     10        \u001b[36m0.9556\u001b[0m        \u001b[32m0.9775\u001b[0m   1.2598\n",
      "     11        \u001b[36m0.9392\u001b[0m        0.9795   1.2039\n",
      "     12        \u001b[36m0.9304\u001b[0m        \u001b[32m0.9680\u001b[0m   1.2781\n",
      "     13        \u001b[36m0.9211\u001b[0m        \u001b[32m0.9523\u001b[0m   1.0703\n",
      "     14        \u001b[36m0.9052\u001b[0m        \u001b[32m0.9424\u001b[0m   1.0538\n",
      "     15        \u001b[36m0.8934\u001b[0m        \u001b[32m0.9255\u001b[0m   1.0067\n",
      "     16        \u001b[36m0.8755\u001b[0m        \u001b[32m0.9220\u001b[0m   0.9895\n",
      "     17        \u001b[36m0.8661\u001b[0m        \u001b[32m0.9039\u001b[0m   1.0665\n",
      "     18        \u001b[36m0.8520\u001b[0m        \u001b[32m0.8934\u001b[0m   0.9974\n",
      "     19        \u001b[36m0.8327\u001b[0m        \u001b[32m0.8709\u001b[0m   1.2918\n",
      "     20        \u001b[36m0.8106\u001b[0m        \u001b[32m0.8485\u001b[0m   1.0149\n",
      "     21        \u001b[36m0.8084\u001b[0m        0.8592   1.0612\n",
      "     22        \u001b[36m0.7706\u001b[0m        \u001b[32m0.7861\u001b[0m   0.9807\n",
      "     23        \u001b[36m0.7527\u001b[0m        \u001b[32m0.7839\u001b[0m   1.1042\n",
      "     24        \u001b[36m0.7278\u001b[0m        \u001b[32m0.7829\u001b[0m   1.1700\n",
      "     25        \u001b[36m0.7138\u001b[0m        \u001b[32m0.7096\u001b[0m   1.1876\n",
      "     26        \u001b[36m0.6894\u001b[0m        \u001b[32m0.6876\u001b[0m   1.3045\n",
      "     27        \u001b[36m0.6570\u001b[0m        \u001b[32m0.6602\u001b[0m   1.1968\n",
      "     28        \u001b[36m0.6437\u001b[0m        \u001b[32m0.6347\u001b[0m   0.9814\n",
      "     29        \u001b[36m0.6057\u001b[0m        \u001b[32m0.6006\u001b[0m   1.1119\n",
      "     30        \u001b[36m0.5810\u001b[0m        \u001b[32m0.5995\u001b[0m   1.0859\n",
      "     31        0.6375        0.6230   1.2987\n",
      "     32        0.5912        \u001b[32m0.5849\u001b[0m   1.0793\n",
      "     33        \u001b[36m0.5696\u001b[0m        \u001b[32m0.5682\u001b[0m   1.1076\n",
      "     34        0.5809        \u001b[32m0.5493\u001b[0m   1.0209\n",
      "     35        \u001b[36m0.5364\u001b[0m        \u001b[32m0.5463\u001b[0m   0.9738\n",
      "     36        \u001b[36m0.5193\u001b[0m        \u001b[32m0.5329\u001b[0m   0.9998\n",
      "     37        \u001b[36m0.5102\u001b[0m        0.5614   0.9995\n",
      "     38        0.5179        \u001b[32m0.5220\u001b[0m   0.9889\n",
      "     39        \u001b[36m0.4883\u001b[0m        \u001b[32m0.5214\u001b[0m   1.0370\n",
      "     40        0.5011        \u001b[32m0.5067\u001b[0m   1.1528\n",
      "     41        0.4924        0.5551   1.0662\n",
      "     42        0.5160        0.5225   1.2452\n",
      "     43        \u001b[36m0.4743\u001b[0m        \u001b[32m0.4883\u001b[0m   1.1614\n",
      "     44        \u001b[36m0.4669\u001b[0m        0.4949   1.1586\n",
      "     45        0.4701        0.5073   1.1884\n",
      "     46        0.4841        0.4913   1.1804\n",
      "     47        \u001b[36m0.4591\u001b[0m        \u001b[32m0.4845\u001b[0m   1.1679\n",
      "     48        \u001b[36m0.4491\u001b[0m        \u001b[32m0.4737\u001b[0m   1.0164\n",
      "     49        0.4746        0.4778   1.1252\n",
      "     50        0.4718        \u001b[32m0.4698\u001b[0m   1.1949\n",
      "Re-initializing optimizer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'ray_sklearn.base.RayTrainNeuralNet'>[initialized](\n",
       "  module_=TabNet(\n",
       "    (embedder): EmbeddingGenerator(\n",
       "      (embeddings): ModuleList(\n",
       "        (0): Embedding(4, 4)\n",
       "        (1): Embedding(13, 7)\n",
       "        (2): Embedding(4, 4)\n",
       "        (3): Embedding(13, 7)\n",
       "        (4): Embedding(4, 4)\n",
       "        (5): Embedding(13, 7)\n",
       "        (6): Embedding(4, 4)\n",
       "        (7): Embedding(13, 7)\n",
       "        (8): Embedding(4, 4)\n",
       "        (9): Embedding(13, 7)\n",
       "      )\n",
       "    )\n",
       "    (tabnet): TabNetNoEmbeddings(\n",
       "      (initial_bn): BatchNorm1d(60, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (encoder): TabNetEncoder(\n",
       "        (initial_bn): BatchNorm1d(60, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (initial_splitter): FeatTransformer(\n",
       "          (shared): GLU_Block(\n",
       "            (shared_layers): ModuleList(\n",
       "              (0): Linear(in_features=60, out_features=48, bias=False)\n",
       "              (1): Linear(in_features=24, out_features=48, bias=False)\n",
       "            )\n",
       "            (glu_layers): ModuleList(\n",
       "              (0): GLU_Layer(\n",
       "                (fc): Linear(in_features=60, out_features=48, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(48, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (1): GLU_Layer(\n",
       "                (fc): Linear(in_features=24, out_features=48, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(48, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (specifics): GLU_Block(\n",
       "            (glu_layers): ModuleList(\n",
       "              (0): GLU_Layer(\n",
       "                (fc): Linear(in_features=24, out_features=48, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(48, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (1): GLU_Layer(\n",
       "                (fc): Linear(in_features=24, out_features=48, bias=False)\n",
       "                (bn): GBN(\n",
       "                  (bn): BatchNorm1d(48, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (feat_transformers): ModuleList(\n",
       "          (0): FeatTransformer(\n",
       "            (shared): GLU_Block(\n",
       "              (shared_layers): ModuleList(\n",
       "                (0): Linear(in_features=60, out_features=48, bias=False)\n",
       "                (1): Linear(in_features=24, out_features=48, bias=False)\n",
       "              )\n",
       "              (glu_layers): ModuleList(\n",
       "                (0): GLU_Layer(\n",
       "                  (fc): Linear(in_features=60, out_features=48, bias=False)\n",
       "                  (bn): GBN(\n",
       "                    (bn): BatchNorm1d(48, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): GLU_Layer(\n",
       "                  (fc): Linear(in_features=24, out_features=48, bias=False)\n",
       "                  (bn): GBN(\n",
       "                    (bn): BatchNorm1d(48, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (specifics): GLU_Block(\n",
       "              (glu_layers): ModuleList(\n",
       "                (0): GLU_Layer(\n",
       "                  (fc): Linear(in_features=24, out_features=48, bias=False)\n",
       "                  (bn): GBN(\n",
       "                    (bn): BatchNorm1d(48, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): GLU_Layer(\n",
       "                  (fc): Linear(in_features=24, out_features=48, bias=False)\n",
       "                  (bn): GBN(\n",
       "                    (bn): BatchNorm1d(48, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (att_transformers): ModuleList(\n",
       "          (0): AttentiveTransformer(\n",
       "            (fc): Linear(in_features=8, out_features=60, bias=False)\n",
       "            (bn): GBN(\n",
       "              (bn): BatchNorm1d(60, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (selector): Sparsemax()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_mapping): Linear(in_features=16, out_features=10, bias=False)\n",
       "    )\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(data, target)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42cdb777d98d67f3b2fb4b742cd32c61d6d0ef1a589fa1e04937806e156b3db0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
